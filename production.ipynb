{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <h1 align=\"center\">CheXRay: Automatically Diagnosing Chest X-Rays using Generated Radiologist Reports and Patient Information </h1>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gdown\n",
    "import gdown\n",
    "    \n",
    "url = \"https://drive.google.com/uc?id=1paplH2kemWuV0IoLTKdkVI9x4TxXhIjW\"\n",
    "output = 'models/sum.0.0.pth'\n",
    "gdown.download(url, output, quiet=True)\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1yS4XJzEI_lIGOraFMoMtqhcCAMxnQzT1\"\n",
    "output = 'models/repgen.0.0.pth'\n",
    "gdown.download(url, output, quiet=True)\n",
    "\n",
    "url = \"https://drive.google.com/u/0/uc?export=download&confirm=7rWd&id=1Pzhd5qdXYWX7zNYBidO-WHKT0CJGJF1H\"\n",
    "output = 'models/txtcls.pkl'\n",
    "gdown.download(url, output, quiet=True)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#Importing libraries and setup\n",
    "#Modules for helper functions\n",
    "from modules.utils.dicom import * #Because PILDicom from fastai doesn't work\n",
    "from modules.utils.tokenizers import *\n",
    "\n",
    "#Modules for fastai.vis\n",
    "#!pip install -q pydicom pyarrow kornia opencv-python scikit-image nbdev\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.medical.imaging import *\n",
    "from fastai.vision.widgets import *\n",
    "\n",
    "#Modules for fastai.text\n",
    "from fastai.text.all import *\n",
    "\n",
    "#Modules for fastai.tab\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "#Modules for R2Gen/multimodal\n",
    "from modules.repgen.dataset import RepGenDataset\n",
    "from modules.repgen.dataloader import *\n",
    "import modules.repgen.logits as log\n",
    "from modules.repgen.model import *\n",
    "from modules.repgen.loss import *\n",
    "from modules.repgen.fastai_utils import *\n",
    "from modules.repgen.metrics import bleu4\n",
    "\n",
    "#Modules for sum\n",
    "from modules.sum.dataloader import SumDL  \n",
    "import modules.sum.logits as log1\n",
    "from modules.sum.model import *\n",
    "from modules.sum.loss import *\n",
    "from modules.sum.fastai_utils import *\n",
    "from modules.sum.metrics import *\n",
    "\n",
    "#Other libraries\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import matplotlib.cm as cm\n",
    "import copy as cp\n",
    "import matplotlib.pylab as plt\n",
    "from decimal import localcontext, Decimal, ROUND_HALF_UP\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageToolPublicAPI('en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Path object which contains path to data\n",
    "prep = Path('./data/')\n",
    "prod_path = Path('./sample/')\n",
    "classes=[\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged_Cardiomediastinum\", \"Fracture\", \n",
    "         \"Lung_Lesion\", \"Lung_Opacity\", \"No_Finding\", \"Pleural_Effusion\", \"Pleural_Other\", \"Pneumonia\", \n",
    "         \"Pneumothorax\", \"Support_Devices\"]\n",
    "views = ['AP','AP_AXIAL','AP_LLD','AP_RLD','PA','PA_LLD','PA_RLD','LATERAL','LL','LAO','RAO','SWIMMERS','XTABLE_LATERAL','LPO']\n",
    "number_views = [144818,\n",
    "                    2,\n",
    "                    2,\n",
    "                    2,\n",
    "                    95145,\n",
    "                    2058,\n",
    "                    339,\n",
    "                    81939,\n",
    "                    42371,\n",
    "                    5188,\n",
    "                    3,\n",
    "                    13,\n",
    "                    2,\n",
    "                    1]\n",
    "workers = multiprocessing.cpu_count()\n",
    "defaults.device = torch.device('cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "beta=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = widgets.HTML(value='<style>p{word-wrap: break-word}</style><p>')\n",
    "heading.value += \"This program takes the patient's chest x-ray(s), formatted as .dcm files, as input and<br/>\"\n",
    "heading.value += \"1) generates a radiologist report using the chest x-ray(s),<br/>\"\n",
    "heading.value += \"2) generates tabular data using the time and date,<br/>\"\n",
    "heading.value += \"3) and generates a summary of the diagnosis alongside heatmap and intrinsic attention visualizations for model interpretability.</p>\"\n",
    "heading.value += \"Notes:<br/>\" \n",
    "heading.value += \"- To upload multiple instances of a view, select all of the instances and upload them all at once.<br/>\"\n",
    "heading.value += \"- Although the x-rays are saved as files in this website, they remain within your environment and are deleted after the website closes.<br/>\"\n",
    "heading.value += \"- You can expect the program to complete within 3-6 minutes.<br/>\"\n",
    "heading.value += \"- Using approximately 8% of the MIMIC-CXR dataset, the report generation model achieves a Bleu4 score of 0.0704 while the diagnosis model achieves a PR-AUC score of .7688, 54.49% precision, 82.41% recall, and an F\" + str(beta) + \" score of .733. A state-of-the-art model to compare these metrics to can be found at https://aclanthology.org/2020.emnlp-main.112.pdf.<br/>\"\n",
    "heading.value += \"- Metrics such as accuracy and ROC AUC were avoided in the optimization of the model and in their reporting because of the dataset's imbalance between positive and negative examples for each condition.\"\n",
    "heading.value += \"- If you have any questions or concerns, please contact the author at the following email: ajhinh@gmail.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_direct = widgets.Label()\n",
    "ap_direct.value = \"If (an) AP view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') #, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_axial_direct = widgets.Label()\n",
    "ap_axial_direct.value = \"If (an) AP axial view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_axial_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_lld_direct = widgets.Label()\n",
    "ap_lld_direct.value = \"If (an) AP LLD view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_lld_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') #, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_rld_direct = widgets.Label()\n",
    "ap_rld_direct.value = \"If (an) AP RLD view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_rld_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_direct = widgets.Label()\n",
    "pa_direct.value = \"If (a) PA view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') #, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_lld_direct = widgets.Label()\n",
    "pa_lld_direct.value = \"If (a) PA LLD view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_lld_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_rld_direct = widgets.Label()\n",
    "pa_rld_direct.value = \"If (a) PA RLD view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_rld_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_direct = widgets.Label()\n",
    "lat_direct.value = \"If (a) lateral view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_direct = widgets.Label()\n",
    "ll_direct.value = \"If (a) LL view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lao_direct = widgets.Label()\n",
    "lao_direct.value = \"If (a) LAO view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lao_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rao_direct = widgets.Label()\n",
    "rao_direct.value = \"If (a) RAO view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rao_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swim_direct = widgets.Label()\n",
    "swim_direct.value = \"If (a) swimmers view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swim_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab_lat_direct = widgets.Label()\n",
    "xtab_lat_direct.value = \"If (a) xtable lateral view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab_lat_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpo_direct = widgets.Label()\n",
    "lpo_direct.value = \"If (a) LPO view instance(s) is/are available, upload it/them here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpo_btn_upload = widgets.FileUpload(multiple=True, accept='.dcm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_report = widgets.Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cond = widgets.Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sumvis = widgets.Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = widgets.HTML(value='<style>p{word-wrap: break-word}</style><p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose = widgets.Button(description='Diagnose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):    \n",
    "    heading.close()\n",
    "    ap_direct.close()\n",
    "    ap_btn_upload.close()\n",
    "    ap_axial_direct.close()\n",
    "    ap_axial_btn_upload.close()\n",
    "    ap_lld_direct.close()\n",
    "    ap_lld_btn_upload.close()\n",
    "    ap_rld_direct.close()\n",
    "    ap_rld_btn_upload.close()\n",
    "    pa_direct.close()\n",
    "    pa_btn_upload.close()\n",
    "    pa_lld_direct.close()\n",
    "    pa_lld_btn_upload.close()\n",
    "    pa_rld_direct.close()\n",
    "    pa_rld_btn_upload.close()\n",
    "    lat_direct.close()\n",
    "    lat_btn_upload.close()\n",
    "    ll_direct.close()\n",
    "    ll_btn_upload.close()\n",
    "    lao_direct.close()\n",
    "    lao_btn_upload.close()\n",
    "    rao_direct.close()\n",
    "    rao_btn_upload.close()\n",
    "    swim_direct.close()\n",
    "    swim_btn_upload.close()\n",
    "    xtab_lat_direct.close()\n",
    "    xtab_lat_btn_upload.close()\n",
    "    lpo_direct.close()\n",
    "    lpo_btn_upload.close()\n",
    "    diagnose.close()\n",
    "    \n",
    "    gen_report.value += \"Generating Report...\"\n",
    "    \n",
    "    input_views = []\n",
    "    input_paths = []\n",
    "\n",
    "    if ap_btn_upload.data!=[]:\n",
    "        input_views.append(\"AP\")\n",
    "        for path in range(len(ap_btn_upload.data)):\n",
    "            temp_path = prod_path/str('AP_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(ap_btn_upload.value[list(ap_btn_upload.value.keys())[0]]['content'])\n",
    "    if ap_axial_btn_upload.data!=[]:\n",
    "        input_views.append(\"AP_AXIAL\")\n",
    "        for path in range(len(ap_axial_btn_upload.data)):\n",
    "            temp_path = prod_path/str('AP_AXIAL_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(ap_axial_btn_upload.value[list(ap_axial_btn_upload.value.keys())[0]]['content'])\n",
    "    if ap_lld_btn_upload.data!=[]:\n",
    "        input_views.append(\"AP_LLD\")\n",
    "        for path in range(len(ap_lld_btn_upload.data)):\n",
    "            temp_path = prod_path/str('AP_LLD_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(ap_lld_btn_upload.value[list(ap_lld_btn_upload.value.keys())[0]]['content'])\n",
    "    if ap_rld_btn_upload.data!=[]:\n",
    "        input_views.append(\"AP_RLD\")\n",
    "        for path in range(len(ap_rld_btn_upload.data)):\n",
    "            temp_path = prod_path/str('AP_RLD_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(ap_rld_btn_upload.value[list(ap_rld_btn_upload.value.keys())[0]]['content'])\n",
    "    if pa_btn_upload.data!=[]:\n",
    "        input_views.append(\"PA\")\n",
    "        for path in range(len(pa_btn_upload.data)):\n",
    "            temp_path = prod_path/str('PA_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(pa_btn_upload.value[list(pa_btn_upload.value.keys())[0]]['content'])\n",
    "    if pa_lld_btn_upload.data!=[]:\n",
    "        input_views.append(\"PA_LLD\")\n",
    "        for path in range(len(pa_lld_btn_upload.data)):\n",
    "            temp_path = prod_path/str('PA_LLD_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(pa_lld_btn_upload.value[list(pa_lld_btn_upload.value.keys())[0]]['content'])\n",
    "    if pa_rld_btn_upload.data!=[]:\n",
    "        input_views.append(\"PA_RLD\")\n",
    "        for path in range(len(pa_rld_btn_upload.data)):\n",
    "            temp_path = prod_path/str('PA_RLD_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(pa_rld_btn_upload.value[list(pa_rld_btn_upload.value.keys())[0]]['content'])\n",
    "    if lat_btn_upload.data!=[]:\n",
    "        input_views.append(\"LATERAL\")\n",
    "        for path in range(len(lat_btn_upload.data)):\n",
    "            temp_path = prod_path/str('LATERAL_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(lat_btn_upload.value[list(lat_btn_upload.value.keys())[0]]['content'])\n",
    "    if ll_btn_upload.data!=[]:\n",
    "        input_views.append(\"LL\")\n",
    "        for path in range(len(ll_btn_upload.data)):\n",
    "            temp_path = prod_path/str('LL_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(ll_btn_upload.value[list(ll_btn_upload.value.keys())[0]]['content'])\n",
    "    if lao_btn_upload.data!=[]:\n",
    "        input_views.append(\"LAO\")\n",
    "        for path in range(len(lao_btn_upload.data)):\n",
    "            temp_path = prod_path/str('LAO_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(lao_btn_upload.value[list(lao_btn_upload.value.keys())[0]]['content'])\n",
    "    if rao_btn_upload.data!=[]:\n",
    "        input_views.append(\"RAO\")\n",
    "        for path in range(len(rao_btn_upload.data)):\n",
    "            temp_path = prod_path/str('RAO_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(rao_btn_upload.value[list(rao_btn_upload.value.keys())[0]]['content'])\n",
    "    if swim_btn_upload.data!=[]:\n",
    "        input_views.append(\"SWIMMERS\")\n",
    "        for path in range(len(swim_btn_upload.data)):\n",
    "            temp_path = prod_path/str('SWIMMERS_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(swim_btn_upload.value[list(swim_btn_upload.value.keys())[0]]['content'])\n",
    "    if xtab_lat_btn_upload.data!=[]:\n",
    "        input_views.append(\"XTABLE_LATERAL\")\n",
    "        for path in range(len(xtab_lat_btn_upload.data)):\n",
    "            temp_path = prod_path/str('XTABLE_LATERAL_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(xtab_lat_btn_upload.value[list(xtab_lat_btn_upload.value.keys())[0]]['content'])\n",
    "    if lpo_btn_upload.data!=[]:\n",
    "        input_views.append(\"LPO\")\n",
    "        for path in range(len(lpo_btn_upload.data)):\n",
    "            temp_path = prod_path/str('LPO_'+str(path)+'.dcm')\n",
    "            input_paths.append(temp_path)\n",
    "            with open(temp_path, 'wb') as f: \n",
    "                f.write(lpo_btn_upload.value[list(lpo_btn_upload.value.keys())[0]]['content'])\n",
    "    \n",
    "    single_repgen_trainval_sample_path = prep/'trainval_sample_repgen_nomiss.csv'\n",
    "    vocab_path = Path('modules/repgen/vocab.pkl')\n",
    "    trainval_sample_single = pd.read_csv(single_repgen_trainval_sample_path)\n",
    "    trainval_sample_single['images']=prod_path/\"AP_0.dcm\"\n",
    "    trainval_sample_single.drop([10728, 10729], inplace=True)\n",
    "    train_sample_single = trainval_sample_single[trainval_sample_single['split']==False]\n",
    "    val_sample_single = trainval_sample_single[trainval_sample_single['split']==True]\n",
    "    train_sample_single.reset_index(drop=True, inplace=True)\n",
    "    val_sample_single.reset_index(drop=True, inplace=True)\n",
    "    with open(vocab_path, 'rb') as f: vocab = pickle.load(f)    \n",
    "        \n",
    "    df = trainval_sample_single.iloc[:len(input_paths)].copy()\n",
    "    df['images'] = input_paths\n",
    "\n",
    "    isval=False\n",
    "    viewtype='images' \n",
    "    ispred=False\n",
    "    train_sample_dataset = RepGenDataset(train_sample_single,isval, viewtype, ispred, classes) \n",
    "    isval=True\n",
    "    val_sample_dataset = RepGenDataset(val_sample_single,isval, viewtype, ispred, classes) \n",
    "    bs=16\n",
    "    trainval_sample_dls = DataLoaders.from_dsets(train_sample_dataset, val_sample_dataset, bs=bs, device=cpu, create_batch=create_batch, num_workers=workers, shuffle=True)\n",
    "    trainval_sample_dls.valid = trainval_sample_dls.valid.new(shuffle=False)\n",
    "\n",
    "    # Model settings (for visual extractor)\n",
    "    visual_extractor='resnet50' #'resnet101'\n",
    "    pretrained=True\n",
    "    # Model settings (for Transformer)  \n",
    "    num_layers=3 #number of layers of Transformer\n",
    "    d_model=512 #dimension of Transformer\n",
    "    d_ff=512 #dimension of FFN\n",
    "    num_heads=8 #number of heads in Transformer\n",
    "    dropout=0.261 #dropout rate of Transformer\n",
    "    use_bn = 0 #whether to use batch normalization\n",
    "    drop_prob_lm = 0.5958\n",
    "    max_seq_len = 100\n",
    "    att_feat_size = 2048 #dimension of the patch features (d_vf in main.py)\n",
    "    ## Not used in original/current, but included in main.py\n",
    "    #parser.add_argument('--logit_layers', type=int, default=1, help='the number of the logit layer.') \n",
    "    # for Relational Memory    \n",
    "    rm_num_slots=3\n",
    "    rm_num_heads=8\n",
    "    rm_d_model=512\n",
    "    # for Sampling\n",
    "    beam_size = 3 #beam size when beam searching\n",
    "    group_size = 1\n",
    "    sample_n = 1 #sample number per image\n",
    "    sample_method = \"beam_search\" #sample methods to sample a report\n",
    "    temperature = 1.0 #temperature when sampling\n",
    "    output_logsoftmax = 1 #whether to output the probabilities\n",
    "    decoding_constraint = 0\n",
    "    block_trigrams = 1\n",
    "    # More params (not in main.py, but used in original/current)\n",
    "    diversity_lambda = 0.5       \n",
    "    input_encoding_size = 512\n",
    "    suppress_UNK = 0 \n",
    "    length_penalty = ''\n",
    "    mode='forward'\n",
    "    model = R2GenModel(visual_extractor,\n",
    "                    pretrained,\n",
    "                    num_layers,\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    num_heads,\n",
    "                    dropout,\n",
    "                    rm_num_slots,\n",
    "                    rm_num_heads,\n",
    "                    rm_d_model,\n",
    "                    vocab,\n",
    "                    input_encoding_size,\n",
    "                    drop_prob_lm,\n",
    "                    max_seq_len,\n",
    "                    att_feat_size,\n",
    "                    use_bn,\n",
    "                    beam_size,\n",
    "                    group_size,\n",
    "                    sample_n,\n",
    "                    sample_method,\n",
    "                    temperature,\n",
    "                    output_logsoftmax,\n",
    "                    decoding_constraint,\n",
    "                    block_trigrams,\n",
    "                    diversity_lambda,\n",
    "                    suppress_UNK,\n",
    "                    length_penalty,\n",
    "                    mode)\n",
    "    model = model.to(cpu)\n",
    "\n",
    "    criterion = compute_loss\n",
    "    metrics = [bleu4] # bleu1, bleu2, bleu3, meteor, rouge, partial(precision, thresh=0.5), partial(recall, thresh=0.5), partial(f1, thresh=0.5)    \n",
    "    wd=3.734e-0\n",
    "\n",
    "    learn = Learner(trainval_sample_dls, model, loss_func=criterion, wd=wd, \n",
    "                    splitter=rep_gen, metrics=metrics, cbs=SelectPred)\n",
    "    learn.load(\"repgen.0.0\", device=cpu)\n",
    "    learn.model.mode='sample'\n",
    "    def passfunc(arg): return arg #Make last arg for learn.predict to not decode anything\n",
    "    def decode(pred): #Convert idx_report to report\n",
    "        words = [] #For every word in report (size rep_len)\n",
    "        for report in pred:\n",
    "            for word in report: #For each word in report\n",
    "                txtword = vocab[word] #word = index for vocab\n",
    "                if txtword not in [word for word in vocab if word[:2]==\"xx\"]: words.append(txtword) \n",
    "        return \" \".join(words)\n",
    "    learn.dls.decode = passfunc\n",
    "    learn.dls.decode_batch = passfunc\n",
    "\n",
    "    rep_input_view = \"\"\n",
    "    if len(input_views)>1:\n",
    "        for i in input_views:\n",
    "            if rep_input_view==\"\": rep_input_view = i\n",
    "            else: \n",
    "                if number_views[views.index(rep_input_view)] < number_views[views.index(i)]: \n",
    "                    rep_input_view = i\n",
    "    else: rep_input_view = input_views[0]\n",
    "        \n",
    "    image = \"\"\n",
    "    for img in input_paths:\n",
    "        temp = str(img).split(\".\")[0].split(\"/\")[1].split(\"_\")[:-1]\n",
    "        if len(temp)==1: \n",
    "            if temp[0]==rep_input_view: \n",
    "                image = img\n",
    "                break\n",
    "        else: \n",
    "            if \"_\".join(temp)==rep_input_view: \n",
    "                image = img\n",
    "                break\n",
    "    \n",
    "    idx = df[df['images']==image].index[0]\n",
    "    ispred=True\n",
    "    pred_dataset = RepGenDataset(df.iloc[idx:idx+1], isval, 'images', ispred, classes)\n",
    "    gts, rep, _ = learn.predict(pred_dataset[idx])\n",
    "    if decode(rep)[-2:] != \" .\" or decode(rep)[-2:] != \". \": report = decode(rep) + ' . '\n",
    "    else: report = decode(rep)\n",
    "    df['reports'] = report\n",
    "\n",
    "    del trainval_sample_dls\n",
    "    del model\n",
    "    del learn\n",
    "    gc.collect()\n",
    "\n",
    "    month = str(datetime.now().month)\n",
    "    if int(month) < 10: month = \"0\"+str(month)\n",
    "    day = str(datetime.now().day)\n",
    "    if int(day) < 10: day = \"0\"+str(day)\n",
    "    df['StudyElapsed'] = str(datetime.now().year)+'-'+month+'-'+day\n",
    "    make_date(df, 'StudyElapsed')\n",
    "    df['StudyElapsed'].values.astype(np.int64) // 10 ** 9\n",
    "    df['Minutes'] = datetime.now().minute\n",
    "    df['Hour'] = datetime.now().hour\n",
    "    df['Seconds'] = datetime.now().second\n",
    "    df['StudyWeek'] = datetime.now().isocalendar()[1]\n",
    "    df['StudyDay'] = datetime.now().day\n",
    "    df['StudyDayofweek'] = datetime.now().isocalendar()[2]\n",
    "    df['StudyDayofyear'] = datetime.now().timetuple().tm_yday\n",
    "    df['StudyElapsed'] = df['StudyElapsed'].values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "    gen_report.close()\n",
    "    id_cond.value = \"Identifying Conditions...\"\n",
    "\n",
    "    size=224\n",
    "    seq_len=72\n",
    "    bs=16\n",
    "    val_bs=len(trainval_sample_single[trainval_sample_single['split']==True])\n",
    "    test_bs=len(df)\n",
    "    train_dls = []\n",
    "    val_dls = []\n",
    "    test_dls = []\n",
    "\n",
    "    with open(Path('./modules/txtcls/vocab.pkl'), 'rb') as f: vocab = pickle.load(f) \n",
    "    cont_nn,cat_nn = cont_cat_split(trainval_sample_single, max_card=365, dep_var=classes)\n",
    "    for frame in [trainval_sample_single, df]:\n",
    "        frame[['Minutes', \n",
    "            'Hour', \n",
    "            'Seconds', \n",
    "            'StudyWeek', \n",
    "            'StudyDay', \n",
    "            'StudyDayofweek', \n",
    "            'StudyDayofyear',\n",
    "            'StudyElapsed']] = frame[['Minutes', \n",
    "                                     'Hour', \n",
    "                                     'Seconds', \n",
    "                                     'StudyWeek', \n",
    "                                     'StudyDay', \n",
    "                                     'StudyDayofweek', \n",
    "                                     'StudyDayofyear',\n",
    "                                     'StudyElapsed']].astype('int32')\n",
    "    def vis_dls(bs, path, istest):\n",
    "        dblock = DataBlock(\n",
    "            blocks=(ImageBlock(cls=PILDicom2), MultiCategoryBlock(encoded=True, vocab=classes)),\n",
    "            get_x=ColReader('images'),\n",
    "            get_y=ColReader(classes),\n",
    "            splitter=istest, \n",
    "            item_tfms=Resize(460),\n",
    "            batch_tfms=[IntToFloatTensor(div=2**16-1),\n",
    "                        Normalize.from_stats(*imagenet_stats),\n",
    "                        *aug_transforms(size=size)]) #, min_scale=0.75: RandomResizedCropGPU not working\n",
    "        return dblock.dataloaders(path, bs=bs, num_workers=workers)\n",
    "\n",
    "    def txt_dls(bs, path, seq_len, istest):\n",
    "        dblock = DataBlock(\n",
    "            blocks=(TextBlock(tok_tfm=BaseTokenizer).from_df(text_cols='reports', vocab=vocab), \n",
    "                    MultiCategoryBlock(encoded=True, vocab=classes)),\n",
    "            get_x=ColReader(cols='text'),\n",
    "            get_y=ColReader(classes),\n",
    "            splitter=istest) \n",
    "        return dblock.dataloaders(path, bs=bs, seq_len=seq_len, num_workers=workers)\n",
    "\n",
    "    def tab_dls(bs, path):\n",
    "        procs_nn = [Categorify, FillMissing, Normalize]\n",
    "        cond = (path.split==False)\n",
    "        train_idx = np.where( cond)[0]\n",
    "        valid_idx = np.where(~cond)[0]\n",
    "        splits = (list(train_idx),list(valid_idx))\n",
    "        return TabularPandas(path, procs_nn, None, cont_nn, splits=splits, y_block=MultiCategoryBlock(encoded=True, vocab=classes), \n",
    "                              y_names=classes).dataloaders(bs, num_workers=workers)\n",
    "\n",
    "    nomiss_repgen_test_path = prep/'test_repgen_nomiss.csv'\n",
    "    test = pd.read_csv(nomiss_repgen_test_path)\n",
    "        \n",
    "    def get_dls(istest):\n",
    "        if istest:\n",
    "            test_dls.append(vis_dls(test_bs, df, ColSplitter('split'))[0].to(\"cpu\"))\n",
    "            test_dls.append(txt_dls(test_bs, df.append(test.iloc[:1], ignore_index=True), seq_len, ColSplitter('split'))[0].to(\"cpu\"))\n",
    "            test_dls.append(tab_dls(test_bs, df)[0].to(\"cpu\"))\n",
    "            return SumDL(*test_dls, device=cpu)\n",
    "        else:\n",
    "            train_dls.append(vis_dls(bs, trainval_sample_single, ColSplitter('split'))[0])\n",
    "            val_dls.append(vis_dls(val_bs, trainval_sample_single, ColSplitter('split'))[1])\n",
    "            train_dls.append(txt_dls(bs, trainval_sample_single, seq_len, ColSplitter('split'))[0])\n",
    "            val_dls.append(txt_dls(val_bs, trainval_sample_single, seq_len, ColSplitter('split'))[1])\n",
    "            train_dls.append(tab_dls(bs, trainval_sample_single)[0])\n",
    "            val_dls.append(tab_dls(val_bs, trainval_sample_single)[1])\n",
    "            train_mixed_dl = SumDL(*train_dls, device=cpu)\n",
    "            valid_mixed_dl = SumDL(*val_dls, device=cpu)\n",
    "            return DataLoaders(train_mixed_dl, valid_mixed_dl)   \n",
    "    mixed_dls = get_dls(False)\n",
    "\n",
    "    def calcHiddenLayer(data, alpha, numHiddenLayers):\n",
    "        i, o = len(list(trainval_sample_single.columns)[2:10]), len(classes)\n",
    "        io = i+o\n",
    "        return [(len(data)//(alpha*(io)))//numHiddenLayers]*numHiddenLayers\n",
    "    \n",
    "    drop_mult=0.3263\n",
    "    model=xresnet18\n",
    "    alpha=2\n",
    "    numHiddenLayers=2\n",
    "    layers=calcHiddenLayer(train_dls[-1], alpha, numHiddenLayers)\n",
    "    txtcls_learn = text_classifier_learner(txt_dls(bs, trainval_sample_single, seq_len, ColSplitter('split')), AWD_LSTM, drop_mult=drop_mult)\n",
    "    unfreeze_name='lang.0.1'\n",
    "    txtcls_learn = txtcls_learn.load_encoder(unfreeze_name)\n",
    "\n",
    "    sum_model = SumModel(cnn_learner(vis_dls(bs, trainval_sample_single, ColSplitter('split')), model).model,\n",
    "                     txtcls_learn.model, \n",
    "                     tabular_learner(tab_dls(bs, trainval_sample_single), layers=layers).model, \n",
    "                     len(classes))\n",
    "\n",
    "    # Set loss_scale for each loss\n",
    "    weights = [3/17, 9/17, 1/17, 4/17]\n",
    "    loss_scale = 1.07\n",
    "    loss = SumGradientBlending(loss_scale, *weights)\n",
    "    \n",
    "    thresh=0.43\n",
    "    \n",
    "    ap_w = partial(ap_weighted, weights=weights)\n",
    "    metrics = [ap_w]\n",
    "\n",
    "    sum_learn = Learner(mixed_dls.to(\"cpu\"), sum_model.to(\"cpu\"), loss, splitter=sum_splitter, metrics=metrics)\n",
    "    sum_learn.freeze_to(-4)\n",
    "    name = 'sum.0.0'\n",
    "    sum_learn.load(name, device=cpu)\n",
    "    sum_learn.dls = sum_learn.dls.to(cpu)\n",
    "    sum_learn.model = sum_learn.model.to(cpu)\n",
    "\n",
    "    del mixed_dls\n",
    "    del model\n",
    "    del sum_model\n",
    "    del txtcls_learn\n",
    "    gc.collect()\n",
    "    \n",
    "    pred_mixed_dls = get_dls(True)\n",
    "    preds,targs = sum_learn.get_preds(dl=pred_mixed_dls)\n",
    "    def decode_prob(preds):\n",
    "        all_inp=0\n",
    "        preds = torch.stack(preds)\n",
    "        for weight in range(len(weights)): all_inp += preds[weight] * weights[weight]\n",
    "        preds = all_inp/len(weights)\n",
    "        preds = preds.sigmoid()\n",
    "        return preds\n",
    "    def decode_rep(preds, thresh=0.5):\n",
    "        preds = decode_prob(preds)\n",
    "        preds[preds>=thresh] = 1\n",
    "        preds[preds<thresh] = 0\n",
    "        return preds\n",
    "\n",
    "    confs = decode_prob(preds)\n",
    "    class_preds = decode_rep(preds, thresh)\n",
    "    \n",
    "    sum_input_views = []\n",
    "    avg_num_view = 2\n",
    "    if len(input_views)>avg_num_view: #Because most studies have two views\n",
    "        for i in input_views:\n",
    "            if len(sum_input_views)<avg_num_view: sum_input_views.append(i)\n",
    "            else: \n",
    "                compare = [number_views[views.index(sum_input_views[j])] for j in range(avg_num_view)]\n",
    "                if number_views[views.index(i)] < min(compare): \n",
    "                    sum_input_views[compare.index(min(compare))] = i\n",
    "    else: sum_input_views.extend(input_views)\n",
    "    num_view = [number_views[views.index(view)] for view in sum_input_views]\n",
    "    sum_input_views = [x for _, x in sorted(zip(num_view, sum_input_views))]\n",
    "    \n",
    "    sum_input_imgs = []\n",
    "    sum_input_idxs = [] #Images that are of view with more examples in front, know with less_view_count\n",
    "    less_view_count = 0\n",
    "    for img in input_paths:\n",
    "        temp = str(img).split(\".\")[0].split(\"/\")[1].split(\"_\")[:-1]\n",
    "        if len(temp)==1: compare = temp[0]\n",
    "        else: compare = \"_\".join(temp)\n",
    "        if compare == sum_input_views[0]: \n",
    "            sum_input_imgs.append(img)\n",
    "            sum_input_idxs.append(df[df['images']==img].index[0])\n",
    "        if len(sum_input_views)>1:\n",
    "            if compare == sum_input_views[1]: \n",
    "                sum_input_imgs.insert(less_view_count, img)\n",
    "                sum_input_idxs.insert(less_view_count, df[df['images']==img].index[0])\n",
    "                less_view_count+=1\n",
    "                \n",
    "    dl_list_idxs = []\n",
    "    for dl in test_dls: \n",
    "        try: dl_list_idxs.append(dl.get_idxs())\n",
    "        except: \n",
    "            temp = []\n",
    "            for idx in dl.get_idxs(): temp.append(idx)\n",
    "            dl_list_idxs.append(temp)\n",
    "    dl_list_idxs = dl_list_idxs[0]   \n",
    "    \n",
    "    del train_dls\n",
    "    del val_dls\n",
    "    del test_dls\n",
    "    gc.collect()\n",
    "    \n",
    "    pred_list_idxs = []\n",
    "    for i in sum_input_idxs: pred_list_idxs.append(dl_list_idxs.index(i))\n",
    "\n",
    "    def get_results(is_pos):\n",
    "        results = []\n",
    "        for i in pred_list_idxs:\n",
    "            temp = []\n",
    "            temp1 = []\n",
    "            for j in range(len(class_preds[i])):\n",
    "                if class_preds[i][j]==is_pos: \n",
    "                    temp.append(classes[j])\n",
    "                    if is_pos: temp1.append(confs[i][j].item())\n",
    "                    else: temp1.append(1 - confs[i][j].item())\n",
    "            results.append({temp[i]: temp1[i] for i in range(len(temp))})\n",
    "        return results\n",
    "    \n",
    "    def get_summary():\n",
    "        neg_results = get_results(0)\n",
    "        pos_results = get_results(1)\n",
    "        confs_select_neg, class_names_neg, confs_select_pos, class_names_pos = [], [], [], []\n",
    "        is_single_img = True if len(pred_list_idxs)<2 else False\n",
    "         \n",
    "        if is_single_img:\n",
    "            def fill_lists(results, select, names):\n",
    "                for condition in classes:\n",
    "                    for dic in results:\n",
    "                        if condition in dic.keys() and condition not in names: \n",
    "                            names.append(condition)\n",
    "                            if len(names) > len(select): select.append(dic[condition])\n",
    "                            else: \n",
    "                                if dic[condition] > select[-1]: select[-1]=dic[condition]\n",
    "                return select, names\n",
    "            confs_select_neg, class_names_neg = fill_lists(neg_results, confs_select_neg, class_names_neg)\n",
    "            confs_select_pos, class_names_pos = fill_lists(pos_results, confs_select_pos, class_names_pos)\n",
    "        else: #Majority vote -> Max Conf -> Pos just to be safe\n",
    "            for condition in classes:\n",
    "                pos_count = np.sum(np.array([condition in dic.keys() for dic in pos_results]))\n",
    "                neg_count = np.sum(np.array([condition in dic.keys() for dic in neg_results]))\n",
    "                def add_to_lists(results, select, names):\n",
    "                    for dic in results:\n",
    "                        if len(names) > len(select): select.append(dic[condition])\n",
    "                        else: \n",
    "                            if dic[condition] > select[-1]: select[-1]=dic[condition]\n",
    "                    return select, names\n",
    "                if pos_count > neg_count:\n",
    "                    class_names_pos.append(condition)\n",
    "                    confs_select_pos, class_names_pos = add_to_lists(pos_results, confs_select_pos, class_names_pos)\n",
    "                elif pos_count < neg_count:\n",
    "                    class_names_neg.append(condition)\n",
    "                    confs_select_neg, class_names_neg = add_to_lists(neg_results, confs_select_neg, class_names_neg)\n",
    "                else:\n",
    "                    max_pos_conf = 0\n",
    "                    max_neg_conf = 0\n",
    "                    for dic in pos_results:\n",
    "                        if dic[condition] > max_pos_conf: max_pos_conf = dic[condition]\n",
    "                    for dic in neg_results:\n",
    "                        if dic[condition] > max_neg_conf: max_neg_conf = dic[condition]\n",
    "                    if max_pos_conf >= max_neg_conf:\n",
    "                        class_names_pos.append(condition)\n",
    "                        confs_select_pos, class_names_pos = add_to_lists(pos_results, confs_select_pos, class_names_pos)\n",
    "                    elif max_pos_conf > max_neg_conf:\n",
    "                        class_names_neg.append(condition)\n",
    "                        confs_select_neg, class_names_neg = add_to_lists(neg_results, confs_select_neg, class_names_neg)\n",
    "        return confs_select_pos, class_names_pos, confs_select_neg, class_names_neg  \n",
    "    \n",
    "    confs_select, class_names, confs_select_neg, class_names_neg = get_summary()\n",
    "    \n",
    "    class_names = [class_names for _, class_names in sorted(zip(confs_select, class_names))]\n",
    "    confs_select = sorted(confs_select, reverse=True)\n",
    "    class_names_neg = [class_names_neg for _, class_names_neg in sorted(zip(confs_select_neg, class_names_neg), reverse=True)]\n",
    "    confs_select_neg = sorted(confs_select_neg, reverse=True)\n",
    "\n",
    "    id_cond.close()\n",
    "    gen_sumvis.value += \"Generating Summary/Interpretability Visualizations...\"\n",
    "\n",
    "    max_memory_num_imgs = 2\n",
    "    idxs = []\n",
    "    for condition in class_names:\n",
    "        pos_results = get_results(1)\n",
    "        for dic in range(len(pos_results)):\n",
    "            if condition in pos_results[dic].keys(): \n",
    "                idxs.append(dic)\n",
    "                if len(idxs)==max_memory_num_imgs: break\n",
    "    sum_input_imgs = [sum_input_imgs[idx] for idx in idxs]\n",
    "    class_idxes = [classes.index(i) for i in class_names]\n",
    "    \n",
    "    def show_gradcam(learn, x, thresh):\n",
    "        class Hook():\n",
    "            def __init__(self, m): self.hook = m.register_forward_hook(self.hook_func)   \n",
    "            def hook_func(self, m, i, o): self.stored = o.detach().clone()\n",
    "            def __enter__(self, *args): return self\n",
    "            def __exit__(self, *args): self.hook.remove()\n",
    "        class HookBwd():\n",
    "            def __init__(self, m):\n",
    "                self.hook = m.register_backward_hook(self.hook_func)   \n",
    "            def hook_func(self, m, gi, go): self.stored = go[0].detach().clone()\n",
    "            def __enter__(self, *args): return self\n",
    "            def __exit__(self, *args): self.hook.remove()\n",
    "        for img in sum_input_imgs:\n",
    "            def cmap(class_idx):\n",
    "                with HookBwd(learn.model.models[0][0]) as hookg: \n",
    "                    with Hook(learn.model.models[0][0]) as hook:\n",
    "                        output = learn.model.eval()(*x[:-1])\n",
    "                        act = hook.stored\n",
    "                    output[0][0][class_idx].backward()\n",
    "                    grad = hookg.stored\n",
    "                return act, grad\n",
    "            for idx in class_idxes:\n",
    "                act, grad = cmap(idx)\n",
    "                w = grad[0].mean(dim=[1,2], keepdim=True)\n",
    "                cam_map = (w * act[0]).sum(0)\n",
    "                x_dec = TensorImage(PILDicom.create(img))\n",
    "                _,ax = plt.subplots()\n",
    "                x_dec.show(ctx=ax, cmap='gray')\n",
    "                ax.imshow(cam_map.detach().cpu(), alpha=0.6, extent=(0,x_dec.shape[0],x_dec.shape[1],0), interpolation='bilinear', cmap='magma');\n",
    "                plt.savefig(Path(str(img)+\",\"+classes[idx]+'.png'), bbox_inches='tight')\n",
    "                del act\n",
    "                del grad\n",
    "                del w\n",
    "                del cam_map\n",
    "                del x_dec\n",
    "                del ax\n",
    "                gc.collect()\n",
    "                \n",
    "    a = pred_mixed_dls.one_batch()\n",
    "    show_gradcam(sum_learn, a, thresh)\n",
    "\n",
    "    def _eval_dropouts(mod):\n",
    "        module_name =  mod.__class__.__name__\n",
    "        if 'Dropout' in module_name or 'BatchNorm' in module_name: mod.training = False\n",
    "        for module in mod.children(): _eval_dropouts(module)\n",
    "    def intrinsic_attention(learn, batch, class_id=None):\n",
    "        \"Calculate the intrinsic attention of the input w.r.t to an output `class_id`, or the classification given by the model if `None`.\"\n",
    "        learn.model.models[1].train()\n",
    "        _eval_dropouts(learn.model)\n",
    "        learn.model.models[1].zero_grad()\n",
    "        learn.model.models[1].reset()\n",
    "        batch = batch[1][0].unsqueeze(0) if len(batch[1].shape)>1 else batch[1]\n",
    "        emb = learn.model.models[1][0].module.encoder(batch).detach().requires_grad_()\n",
    "        emb.retain_grad()\n",
    "        lstm = learn.model.models[1][0].module(emb, True)\n",
    "        learn.model.models[1].eval()\n",
    "        cl = learn.model.models[1][1]((lstm, torch.zeros_like(batch).bool(),))[0].softmax(dim=-1)\n",
    "        if class_id is None: class_id = cl.argmax()\n",
    "        cl[0][class_id].backward()\n",
    "        attn = emb.grad.squeeze().abs().sum(dim=-1)\n",
    "        attn /= attn.max()\n",
    "\n",
    "        b = report.split(\" . \")\n",
    "        views1 = [view.lower() for view in views]\n",
    "        rep = dict(zip(views1, views))\n",
    "        def replace_all(text, dic):\n",
    "            for i, j in dic.items(): text = text.replace(\" \"+i, \" \"+j).replace(i+\" \", j+\" \").replace(\" \"+i+\" \", \" \"+j+\" \")\n",
    "            return text\n",
    "        c = [replace_all(x, rep) for x in b]\n",
    "        d = \". \".join(c)\n",
    "        e = d[:-1]\n",
    "        text = tool.correct(e)\n",
    "        text = re.sub(r'(\\s)xx\\w+', \"\", text, flags=re.IGNORECASE)   \n",
    "        if text[-1]!=\".\": text = text + \".\"\n",
    "        return text, attn\n",
    "    def value2rgba(x, cmap=cm.Purples, alpha_mult=1.0):\n",
    "        \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n",
    "        c = cmap(x)\n",
    "        rgb = (np.array(c[:-1]) * 255).astype(int)\n",
    "        a = c[-1] * alpha_mult\n",
    "        return tuple(rgb.tolist() + [a])\n",
    "    def piece_attn_html(pieces, attns, sep=' ', **kwargs):\n",
    "        html_code,spans = ['<span style=\"font-family: monospace;\">'], []\n",
    "        for p, a in zip(pieces, attns):\n",
    "            p = html.escape(p)\n",
    "            c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n",
    "            spans.append(f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>')\n",
    "        html_code.append(sep.join(spans))\n",
    "        html_code.append('</span>')\n",
    "        return ''.join(html_code)\n",
    "    def show_piece_attn(*args, **kwargs):\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML(piece_attn_html(*args, **kwargs)))\n",
    "    def html_intrinsic_attention(learn, x:tuple, class_id:int=None, **kwargs)->str:\n",
    "        text, attn = intrinsic_attention(learn, x, class_id)\n",
    "        return piece_attn_html(text.split(), to_np(attn), **kwargs)\n",
    "    def show_intrinsic_attention(learn, x:tuple, class_id:int=None, **kwargs)->None:\n",
    "        text, attn = intrinsic_attention(learn, x, class_id)\n",
    "        show_piece_attn(text.split(), to_np(attn), **kwargs)     \n",
    "    for class_name in class_names:\n",
    "        with open(prod_path/Path(class_name+'.txt'), \"wt\") as txt:\n",
    "            txt.write(html_intrinsic_attention(sum_learn, a, classes.index(class_name)))\n",
    "            txt.close()\n",
    "    #\"\"\"\n",
    "    def display_both(learn, x, thresh):\n",
    "        class Hook():\n",
    "            def __init__(self, m): self.hook = m.register_forward_hook(self.hook_func)   \n",
    "            def hook_func(self, m, i, o): self.stored = o.detach().clone()\n",
    "            def __enter__(self, *args): return self\n",
    "            def __exit__(self, *args): self.hook.remove()\n",
    "        class HookBwd():\n",
    "            def __init__(self, m):\n",
    "                self.hook = m.register_backward_hook(self.hook_func)   \n",
    "            def hook_func(self, m, gi, go): self.stored = go[0].detach().clone()\n",
    "            def __enter__(self, *args): return self\n",
    "            def __exit__(self, *args): self.hook.remove()\n",
    "\n",
    "        txts = []\n",
    "        for class_name in class_names:\n",
    "            with open(prod_path/Path(class_name+'.txt')) as txt:\n",
    "                lines = txt.readlines()\n",
    "                txts.append([lines[0]])\n",
    "\n",
    "        # Create a dataframe using pandas library\n",
    "        data = pd.DataFrame(columns = ['Conditions', 'Report_Interpretation'])\n",
    "        for idx in class_idxes:\n",
    "            for i in sum_input_imgs:\n",
    "                data.loc[class_idxes.index(idx), str(i).split(\"/\")[1].split(\".\")[0]] = str(i)+\",\"+classes[idx]+'.png'\n",
    "            data.loc[class_idxes.index(idx), 'Conditions'] = classes[idx]\n",
    "            data.loc[class_idxes.index(idx), 'Report_Interpretation'] = txts[class_idxes.index(idx)] if type(txts[class_idxes.index(idx)])!=list else txts[class_idxes.index(idx)][0]\n",
    "        data.set_index('Conditions', inplace=True)\n",
    "\n",
    "        # Converting links to html tags\n",
    "        def path_to_image_html(path): \n",
    "            img = str(path).split(\",\")[0]\n",
    "            x_dec = TensorImage(PILDicom.create(img))\n",
    "            return '<img src=\"'+ path + '\" width=\"'+ str(int(x_dec.shape[0])) + '\" height=\"'+ str(int(x_dec.shape[1])) + '\">'\n",
    "\n",
    "        # Rendering the dataframe as HTML table\n",
    "        data.to_html(escape=False, formatters={str(img).split(\"/\")[1].split(\".\")[0]:path_to_image_html for img in sum_input_imgs})\n",
    "        out_pl.clear_output()\n",
    "        gen_sumvis.close()\n",
    "        summary.value += \"Given a confidence threshold of \"+str(thresh)+\",<br/> which is the minimum confidence the model must have in order to give a positive diagnosis for a disease,<br/> and is the ideal confidence for maximizing the F\" + str(beta) + \" score as determined by the validation set,<br/>\"\n",
    "        if len(class_names)<1:\n",
    "            summary.value += \"this patient's condition cannot be determined. Please contact them to collect another set of x-rays.<br/>\"\n",
    "        else:\n",
    "            summary.value += \"this patient most likely needs to get checked out for the following conditions:<br/>\"\n",
    "            if len(class_names)<2:\n",
    "                summary.value += class_names[0] + f\"({confs_select[0]*100:.2f}% confident).<br/>\"\n",
    "            else:\n",
    "                for idx in range(len(class_names)-1):\n",
    "                    summary.value += class_names[idx] + f\"({confs_select[idx]*100:.2f}% confident),<br/>\"\n",
    "                temp_idx = len(class_names)-1\n",
    "                summary.value += \"and \" + class_names[temp_idx] + f\"({confs_select[temp_idx]*100:.2f}% confident).<br/>\"\n",
    "            summary.value += \"<br/>This patient most likely doesn't need to get checked out for the following conditions:<br/>\"\n",
    "            if len(class_names_neg)<2:\n",
    "                summary.value += class_names_neg[0] + f\"({confs_select_neg[0]*100:.2f}% confident).<br/>\"\n",
    "            else:    \n",
    "                for idx in range(len(class_names_neg)-1):\n",
    "                    summary.value += class_names_neg[idx] + f\"({confs_select_neg[idx]*100:.2f}% confident),<br/>\"\n",
    "                temp_idx = len(class_names_neg)-1\n",
    "                summary.value += \"and \" + class_names_neg[temp_idx] + f\"({confs_select_neg[temp_idx]*100:.2f}% confident).<br/>\"\n",
    "        summary.value += ' </p>'\n",
    "        with out_pl: display(HTML(data.to_html(escape=False,formatters={str(img).split(\"/\")[1].split(\".\")[0]:path_to_image_html for img in sum_input_imgs}))) \n",
    "    display_both(sum_learn, a, thresh)\n",
    "    #\"\"\"            \n",
    "diagnose.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VBox([heading, \n",
    "      ap_direct, \n",
    "      ap_btn_upload,\n",
    "      ap_axial_direct,\n",
    "      ap_axial_btn_upload,\n",
    "      ap_lld_direct,\n",
    "      ap_lld_btn_upload,\n",
    "      ap_rld_direct,\n",
    "      ap_rld_btn_upload,\n",
    "      pa_direct,\n",
    "      pa_btn_upload,\n",
    "      pa_lld_direct,\n",
    "      pa_lld_btn_upload,\n",
    "      pa_rld_direct,\n",
    "      pa_rld_btn_upload,\n",
    "      lat_direct, \n",
    "      lat_btn_upload, \n",
    "      ll_direct,\n",
    "      ll_btn_upload,\n",
    "      lao_direct,\n",
    "      lao_btn_upload,\n",
    "      rao_direct,\n",
    "      rao_btn_upload,\n",
    "      swim_direct,\n",
    "      swim_btn_upload,\n",
    "      xtab_lat_direct,\n",
    "      xtab_lat_btn_upload,\n",
    "      lpo_direct,\n",
    "      lpo_btn_upload,\n",
    "      diagnose,\n",
    "      gen_report,\n",
    "      id_cond,\n",
    "      gen_sumvis,\n",
    "      summary,\n",
    "      out_pl],\n",
    "     layout=Layout(width='100%', display='flex', align_items='center'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
